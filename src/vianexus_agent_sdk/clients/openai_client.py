import logging
from openai import OpenAI
import os
import json
from vianexus_agent_sdk.clients.setup.enhanced_mcp_client import EnhancedMCPClient

class OpenAiClient(EnhancedMCPClient):
    """
    OpenAI-specific MCP client that uses ChatGPT for processing queries.
    Inherits common MCP functionality from EnhancedMCPClient.
    """
    
    def __init__(self, config=None, config_path="config.yaml", env="development"):
        super().__init__(config, config_path, env)
        self.openai = OpenAI(api_key=os.environ.get("OPENAI_API_KEY"))
    
    def format_schema(self, schema: dict) -> dict:
        '''
        Format the schema for acceptance by the OpenAI API.
        '''
        if 'additionalProperties' not in schema:
            schema['additionalProperties'] = False
        schema['required'] = list(schema['properties'].keys())
        logging.info(f"Formatted schema: {schema}")
        return schema
    
    async def get_tool_list(self):
        '''
        Get the list of tools from the MCP server.
        TODO Format this for acceptance by the OpenAI API.
        '''
        tool_list = await self.session.list_tools()
        formatted_tools = []
        for tool in tool_list.tools:
            formatted_tools.append({
                "type": "function",
                "name": tool.name,
                "description": tool.description,
                "parameters": self.format_schema(tool.inputSchema),
                "strict": True,
            })
        return formatted_tools
    
    async def process_query(self, query: str) -> str:
        """Process a query using ChatGPT and available tools"""
        if not self.session:
            return "Error: MCP session not initialized. Please check the connection."
        
        final_text = []
        messages = [
            {
                "role": "user",
                "content": query
            }
        ] 
        tools = await self.get_tool_list()
        response = self.openai.responses.create(
            model="gpt-4o-mini",
            tools=tools,
            input=messages,
        )

        # Save function call outputs for subsequent requests
        function_call = None
        function_call_arguments = None
        messages += response.output

        for item in response.output:
            if item.type == "function_call":
                logging.info(f"Function call: {item}")
                function_call = item
                function_call_arguments = json.loads(item.arguments)
                result = await self.session.call_tool(function_call.name, function_call_arguments)
                messages.append({
                    "type": "function_call_output",
                    "call_id": function_call.call_id,
                    "output": str(result.content),
                })

                response = self.openai.responses.create(
                    model="gpt-4o-mini",
                    instructions="Respond only with a horoscope generated by a tool.",
                    tools=tools,
                    input=messages,
                )

                # 5. The model should be able to give a response!
                final_text.append(response.output_text)

        return "\n".join(final_text)
